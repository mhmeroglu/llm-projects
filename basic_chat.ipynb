{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vX2mmtPvi4u3"
      },
      "outputs": [],
      "source": [
        "!pip install google-generativeai -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get API key"
      ],
      "metadata": {
        "id": "mtqvq5Krp_-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import textwrap\n",
        "import time\n",
        "\n",
        "import google.generativeai as genai\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown"
      ],
      "metadata": {
        "id": "9ykiQ3yfjUfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def to_markdown(text):\n",
        "  text = text.replace('•', '  *')\n",
        "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ],
      "metadata": {
        "id": "ETedc_sIoEMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "OAZMGRaDkbZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "XmolHf0wmCTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"How many synonyms can be mentioned for the word 'dessert'?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "LQxlefrjolpo",
        "outputId": "169f42c9-f7b3-4220-8e8d-5ff7e6682f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> The number of synonyms for \"dessert\" depends on how broadly you define \"synonym.\"  A direct synonym is rare.  However, you could list many words that describe similar things or situations:\n> \n> * **Sweet:** This is probably the closest single word synonym, though it's more of a descriptor.\n> * **Afters:**  Common British English term\n> * **Sweet course:** More formal\n> * **Pudding:** (British English, often a specific type of dessert)\n> * **Treat:**  Focuses on the enjoyable aspect\n> * **Sweets:**  (Plural, refers to multiple sweet items)\n> * **Confection:**  Focuses on the prepared, often sugary, nature\n> * **Pastry:**  If the dessert is pastry-based\n> \n> \n> You could also list more specific types of desserts (cake, pie, ice cream, etc.), but these are not true synonyms.  Therefore,  a definitive number is hard to give, but  a dozen or more words could reasonably be considered synonyms or near-synonyms depending on context.\n"
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"Can you give me those desserts you just gave to me as a list?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "Vb7XlMejqgxj",
        "outputId": "67304c53-54e4-4554-f933-8cf9dab05640"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> As an AI, I have no memory of past conversations.  To get a list of desserts, please tell me what desserts you'd like!\n"
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history=[])\n",
        "response = chat.send_message(\"What would you do if you were a human being and saw a black duck in an oven?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "ubqf9ZAaZsB3",
        "outputId": "54a39d06-35e9-429e-d265-8fcd2617326d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> If I were a human being and saw a black duck in an oven, my immediate actions would depend heavily on the context:\n> \n> * **Is the oven on?**  If the oven is on and hot, I'd immediately turn it off and remove the duck.  My next action would be to assess the duck's condition – is it alive? Injured?  If it's alive, I'd try to provide it with care (water, a safe place to recover). If it's dead, I'd need to figure out how it got there and whether foul play was involved.\n> \n> * **Is the oven off?** If the oven is off, I'd still be concerned.  Why is a duck in the oven? Is it someone's (poorly thought-out) cooking project?  Is it lost?  I might try to find out who owns the duck and where it should be.\n> \n> * **Is it a pet duck?** If I know the duck is a pet, I'd contact the owner immediately.  Perhaps they forgot about it.\n> \n> In any case, finding a duck in an oven is highly unusual. I would likely investigate the situation and act to ensure the duck's safety and well-being.  I might also report the situation to animal control or the appropriate authorities if I suspected animal cruelty.\n"
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response =chat.send_message(\"What was the name and color of the duck in the oven I asked to you\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "id": "XmwAcvztRZZZ",
        "outputId": "9ecec578-b997-41a9-c1b8-e281c33ed88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> You didn't specify the name or color of the duck in your previous question. You only said \"a black duck\".  I responded based on that information.\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What would you do if you were a human being and saw a black duck in an oven?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "3jU1gS28PHBY",
        "outputId": "26acf80b-def1-4acb-fb73-d28608f51635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> If I were a human and saw a black duck in an oven, my immediate reaction would depend heavily on the context.  Here are a few possibilities and my likely responses:\n> \n> * **If the oven was on and the duck appeared to be cooking:** I'd be incredibly concerned.  This strongly suggests animal cruelty. I'd immediately turn off the oven, remove the duck (carefully, to avoid burns), and assess its condition. If it was alive and suffering, I'd seek veterinary help immediately. If it was already dead, I'd investigate further to determine how it died and report any suspected cruelty to the appropriate authorities (animal control, RSPCA/equivalent).\n> \n> * **If the oven was off and the duck appeared to be unharmed:** I'd be confused.  Why is a duck in the oven?  I'd likely try to figure out who put it there and why.  Was it a child playing?  Was it an accident?  Was it part of a larger, perhaps bizarre, situation?  I'd aim to find a reasonable explanation.\n> \n> * **If the oven was on and the duck was clearly prepared for cooking (e.g., seasoned, etc.):**  My reaction would depend on my own ethical stance on eating meat. If I'm a vegetarian/vegan, I'd be highly uncomfortable and likely remove the duck and dispose of it appropriately.  If I eat meat, I'd still question the origin of the duck and ensure it was ethically sourced.\n> \n> In short, seeing a duck in an oven would trigger a range of responses from concern and potential action to confusion and investigation.  My priority would be the welfare of the animal.\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash-latest')\n",
        "#response = model.generate_content(\"How many different ways to acccess a model in the Gemini API?\")\n",
        "chat = model.start_chat(history=[])\n",
        "response = chat.send_message(\"What would you do if you were a human being and saw a black duck in an oven?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "B3Ec58pDolmB",
        "outputId": "82b78e48-b84b-49db-d1d3-fdd0978f321f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> If I saw a black duck in an oven, my immediate reaction as a human being would depend heavily on the context.  \n> \n> **Scenario 1: The duck is clearly meant to be cooked.**  This is the most likely scenario. I'd probably assume it was dinner and leave it alone, unless I was involved in the cooking process.\n> \n> **Scenario 2: The duck is alive and appears distressed.** This is a far more concerning scenario. I would immediately remove the duck from the oven and assess its condition. I would then try to find out who put it there and why. Depending on the duck's condition, I might seek veterinary help.\n> \n> **Scenario 3: The duck is dead, but not obviously prepared for cooking.** This would be suspicious. I'd be concerned that something untoward had happened. I might investigate further, possibly contacting animal control or the authorities depending on the circumstances.\n> \n> \n> In short, my actions would range from doing nothing to calling for help, all depending on whether the duck was alive, distressed, or simply part of a meal.\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response =chat.send_message(\"What was the name and color of the duck in the oven I asked to you\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "hkF9mMIargBu",
        "outputId": "bf0a2f7d-4b70-4eaa-d034-edfe0e7d5272"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> You didn't specify the name or color of the duck in your previous question.  You only stated that it was a black duck.  I responded based on that information.\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Chat implementation"
      ],
      "metadata": {
        "id": "E6d8KXYWqYlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt= \"\"\" As an academic assistant for any engineering stuffs, you are supposed to provide assistance for several ideas\n",
        "           and how those dreams would become true in real life on different situations.\n",
        "           I will provide you the question and related text.\n",
        "           Answer the following questions, ensuring your responses\n",
        "           are derived exclusively from the provided partial texts.\n",
        "           If the answer cannot be found within the provided excerpts,\n",
        "           kindly respond with 'I don't know'.\n",
        "           If you are ready, I will provide you the question and related text.\n",
        "        \"\"\""
      ],
      "metadata": {
        "id": "rlt1sRp4sWCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel('gemini-1.5-flash-latest', system_instruction=system_prompt)\n",
        "chat = model.start_chat(history=[])"
      ],
      "metadata": {
        "id": "3lbXP1STuTwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUS3X6_EuXCr",
        "outputId": "a1458cb3-8d7d-403b-bbe8-98c952808e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-1.5-flash-latest',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=\" As an academic assistant for any engineering stuffs, you are supposed to provide assistance for several ideas\\n           and how those dreams would become true in real life on different situations.\\n           I will provide you the question and related text.\\n           Answer the following questions, ensuring your responses\\n           are derived exclusively from the provided partial texts.\\n           If the answer cannot be found within the provided excerpts,\\n           kindly respond with 'I don't know'.\\n           If you are ready, I will provide you the question and related text.\\n        \",\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"What is your task? \"\n",
        "response = chat.send_message(prompt)\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "ld1T6p2Puaje",
        "outputId": "87155f5f-2558-44e0-efbf-694f2b431db0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> My task is to act as an academic assistant for engineering-related topics.  I will provide assistance on different ideas and explain how those ideas could become real-life applications in various situations.  I will answer questions based solely on the provided text excerpts. If a question cannot be answered using the provided text, I will respond with \"I don't know\".\n"
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt=\"Tell me something about you\"\n",
        "response = chat.send_message(prompt)\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "mCMeZeyxlvs7",
        "outputId": "c86a6cd9-86cf-43bb-d111-4e43f63cb9b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> I am a large language model, trained by Google.  I am designed to assist with engineering-related questions and to explain how theoretical ideas might be implemented in real-world scenarios. My responses are based solely on the information provided to me; if I don't have the information, I will say \"I don't know\".\n"
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat.history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQt4poBPugfY",
        "outputId": "4a7c8c00-8fc1-452f-e63f-e7337ef55d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"What is your task? \"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"My task is to act as an academic assistant for engineering-related topics.  I will provide assistance on different ideas and explain how those ideas could become real-life applications in various situations.  I will answer questions based solely on the provided text excerpts. If a question cannot be answered using the provided text, I will respond with \\\"I don\\'t know\\\".\\n\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Tell me something about you\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"I am a large language model, trained by Google.  I am designed to assist with engineering-related questions and to explain how theoretical ideas might be implemented in real-world scenarios. My responses are based solely on the information provided to me; if I don\\'t have the information, I will say \\\"I don\\'t know\\\".\\n\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}